from export.vdb_export import ExportVDB
import pinecone
import os
import json
import pandas as pd
import numpy as np
import sqlite3
import sqlite3
import pyarrow as pa
import pyarrow.parquet as pq
import json
from dotenv import load_dotenv



class ExportPinecone(ExportVDB):
    def __init__(self, args):
        load_dotenv()
        pinecone_api_key = os.getenv("PINECONE_API_KEY")
        if pinecone_api_key is None:
            raise ValueError("PINECONE_API_KEY is not set in the .env file")
        pinecone.init(api_key=pinecone_api_key, environment=args.environment)
        self.index_name = args.index
        
    def get_all_index_names(self):
        return pinecone.list_indexes()

    def get_ids_from_query(self,index,input_vector):
        print("searching pinecone...")
        results = index.query(vector=input_vector,include_values=True,top_k=100)
        ids = set()
        print(type(results))
        for result in results['matches']:
            ids.add(result['id'])
        return ids

    def get_all_ids_from_index(self,index, num_dimensions, namespace=""):
        num_vectors = index.describe_index_stats()["namespaces"][namespace]['vector_count']
        all_ids = set()
        while len(all_ids) < num_vectors:
            print("Length of ids list is shorter than the number of total vectors...")
            input_vector = np.random.rand(num_dimensions).tolist()
            print("creating random vector...")
            ids = self.get_ids_from_query(index,input_vector)
            print("getting ids from a vector query...")
            all_ids.update(ids)
            print("updating ids set...")
            print(f"Collected {len(all_ids)} ids out of {num_vectors}.")

        return all_ids

    def get_data(self, index_name):
        self.index = pinecone.Index(index_name=self.index_name)
        info = self.index.describe_index_stats()
        namespace = info["namespaces"]
        zero_array = [0] * info["dimension"]

        vdf_directory = "VDF_dataset"
        vectors_directory = os.path.join(vdf_directory, "vectors")
        os.makedirs(vdf_directory, exist_ok=True)
        os.makedirs(vectors_directory, exist_ok=True)
        # Fetch the actual data from the Pinecone index
        
        data = self.index.fetch(list(self.get_all_ids_from_index(index=pinecone.Index(self.index_name),num_dimensions=8)))

        vectors = data['vectors']

        # Create a SQLite database for metadata
        conn = sqlite3.connect(os.path.join(vdf_directory, "metadata.db"))
        c = conn.cursor()

        # Get the keys from the metadata of the first vector
        metadata_keys = list(next(iter(vectors.values()))['metadata'].keys())

        # Create a string for the SQL command
        sql_command = "CREATE TABLE metadata (id text, " + ", ".join([f"{key} text" for key in metadata_keys]) + ")"

        # Delete the table if it already exists
        c.execute('''DROP TABLE IF EXISTS metadata''')

        # Create table
        c.execute(sql_command)

        # Insert data into the table
        for vector_id, vector_data in vectors.items():
            c.execute("INSERT INTO metadata VALUES (?, " + ", ".join(["?" for _ in metadata_keys]) + ")",
                      (vector_id, *vector_data['metadata'].values()))

        # Save (commit) the changes and close the connection
        conn.commit()
        conn.close()


        # Create a Parquet file for vectors
        vectors_df = pd.DataFrame([(vector_id, vector_data['values']) for vector_id, vector_data in vectors.items()],
                                  columns=['id', 'vector'])
        table = pa.Table.from_pandas(vectors_df)
        pq.write_table(table, os.path.join(vectors_directory, "part-1.parquet"), compression='snappy')

        # Create a JSON file for internal metadata
        with open(os.path.join(vdf_directory, "VDF_META.json"), 'w') as f:
            json.dump({
                'version': '1.0',
                'author': 'Unknown',
                'dataset_name': index_name,
                'dataset_size': len(vectors),
                'license': 'Unknown',
                'description': 'Exported from Pinecone'
            }, f)
